{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320756ad-74bc-4bb9-9af6-8a2c00cc7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8835dc7-54dd-4a8e-867e-5d0ab3116479",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"How AP reported in all formats from tornado-stricken regionsMarch 8, 2012 When the first serious bout of tornadoes of 2012 blew through middle America in the middle of the night, they touched down in places hours from any AP bureau. Our closest video journalist was Chicago-based Robert Ray, who dropped his plans to travel to Georgia for Super Tuesday, booked several flights to the cities closest to the strikes and headed for the airport. He’d decide once there which flight to take. He never got on board a plane. Instead, he ended up driving toward Harrisburg, Ill., where initial reports suggested a town was destroyed. That decision turned out to be a lucky break for the AP. Twice. Ray was among the first journalists to arrive and he confirmed those reports -- in all formats. He shot powerful video, put victims on the phone with AP Radio and played back sound to an editor who transcribed the interviews and put the material on text wires. He then walked around the devastation with the Central Regional Desk on the line, talking to victims with the phone held so close that editors could transcribe his interviews in real time. Ray also made a dramatic image of a young girl who found a man’s prosthetic leg in the rubble, propped it up next to her destroyed home and spray-painted an impromptu sign: “Found leg. Seriously.” The following day, he was back on the road and headed for Georgia and a Super Tuesday date with Newt Gingrich’s campaign. The drive would take him through a stretch of the South that forecasters expected would suffer another wave of tornadoes. To prevent running into THAT storm, Ray used his iPhone to monitor Doppler radar, zooming in on extreme cells and using Google maps to direct himself to safe routes. And then the journalist took over again. “When weather like that occurs, a reporter must seize the opportunity to get the news out and allow people to see, hear and read the power of nature so that they can take proper shelter,” Ray says. So Ray now started to use his phone to follow the storms. He attached a small GoPro camera to his steering wheel in case a tornado dropped down in front of the car somewhere, and took video of heavy rain and hail with his iPhone. Soon, he spotted a tornado and the chase was on. He followed an unmarked emergency vehicle to Cleveland, Tenn., where he was first on the scene of the storm's aftermath. Again, the tornadoes had struck in locations that were hours from the nearest AP bureau. Damage and debris, as well as a wickedly violent storm that made travel dangerous, slowed our efforts to get to the news. That wasn’t a problem in Tennessee, where our customers were well served by an all-formats report that included this text story. “CLEVELAND, Tenn. (AP) _ Fierce wind, hail and rain lashed Tennessee for the second time in three days, and at least 15 people were hospitalized Friday in the Chattanooga area.” The byline? Robert Ray. For being adept with technology, chasing after news as it literally dropped from the sky and setting a standard for all-formats reporting that put the AP ahead on the most competitive news story of the day, Ray wins this week’s $300 Best of the States prize. © 2013 The Associated Press. All rights reserved. Terms and conditions apply. See AP.org for details.\"\n",
    "\n",
    "\n",
    "re1 = \"\"\"Breaking News: Tornadoes Devastate Midwest and Southern States - AP Reporting\n",
    "Harrisburg, IL & Cleveland, TN — In a week marked by extreme weather, communities across Middle America are reeling from the destruction left by a series of powerful tornadoes that tore through the Midwest and Southern states. The Associated Press was among the first on the scene, dispatching a multi-format team led by seasoned Chicago-based journalist Robert Ray. Ray's agility and adaptability in field reporting brought real-time coverage to the nation, integrating text, audio, and video formats for comprehensive, up-to-the-minute updates on the devastation.\n",
    "Utilizing everything from Doppler radar monitoring to GPS tracking via iPhone and Google Maps, the AP team navigated storm-ravaged landscapes and coordinated coverage across various bureaus, including the Central Regional Desk, to report from the heart of the chaos. This approach allowed Ray and his team to provide a continuous flow of crucial information to communities in the path of these violent storms, combining raw footage captured on GoPro cameras with on-the-ground interviews and dramatic photojournalism capturing the scale of damage and resilience of the tornado-stricken regions.\n",
    "In Harrisburg, Illinois, and Cleveland, Tennessee—two of the hardest-hit locations—AP journalists braved dangerous conditions to document the aftermath and share the harrowing stories of survivors. Eyewitness accounts, recorded in improvised settings and in the midst of debris and emergency response efforts, provided an unfiltered look into the lives affected by nature’s fury. Their commitment to public safety awareness ensured that, despite chaotic and dangerous conditions, audiences were kept informed through live updates and visually compelling reports.\n",
    "AP Radio and associated video platforms distributed the coverage widely, emphasizing the AP’s dedication to competitive journalism in adverse conditions. The team’s relentless reporting earned them the “Best of the States” award and a $300 prize, recognized for both their agility in delivering on-the-ground tornado tracking during the intense 2012 tornado season and their journalistic courage.\n",
    "Simultaneously, AP’s coverage managed to connect these stories to the broader national context, including the intersecting political news of Newt Gingrich's campaign as Super Tuesday approached. By integrating disaster updates with high-profile political developments, the Associated Press demonstrated the power and flexibility of all-format journalism, ultimately enhancing audience engagement and providing critical insight into a week of extraordinary challenges for the American South.\n",
    "This high-stakes, multi-format coverage underscores the essential role of agile, all-format reporting teams in capturing the power of nature and the strength of communities faced with natural disasters. Through their commitment and field adaptability, AP journalists like Robert Ray continue to set a standard for excellence in real-time reporting on extreme weather events.\n",
    "\"\"\"\n",
    "re2 = \"\"\"**AP Breaking News: Tornadoes Devastate Midwest, Coverage Highlights Destruction and Survival**\n",
    "\n",
    "*Harrisburg, IL & Cleveland, TN* — As deadly tornadoes ripped through the Midwest and South, AP reporter Robert Ray was on the ground with a straightforward, multi-format approach to bring immediate updates to the nation. Covering the disaster solo, Ray quickly arrived in Harrisburg, Illinois, and Cleveland, Tennessee, navigating storm paths in real-time using Doppler radar and Google Maps for safety and precision. His commitment to delivering breaking news involved a seamless integration of video, audio, and text updates, all of which were coordinated through the AP Central Regional Desk.\n",
    "\n",
    "Ray’s setup—an iPhone for GPS, a GoPro camera mounted to his steering wheel, and real-time decision-making on the road—allowed him to capture and relay the tornado's destruction and resilience in affected communities. He recorded the damage, conducted phone interviews with survivors, and documented the emergency response unfolding around him. His photojournalism offered viewers a stark view of the destruction, while direct interviews with victims and eyewitnesses captured powerful stories of survival amid nature’s unpredictability.\n",
    "\n",
    "This real-time coverage was not only a testament to Ray’s agility and courage in dangerous conditions but also to AP's dedication to immediate, all-format reporting that prioritized public safety alerts and awareness. Live updates provided critical information as the storm continued its path, reinforcing the importance of timely communication in the face of extreme weather.\n",
    "\n",
    "For his exhaustive efforts in capturing the intense 2012 tornado season, Ray’s reporting was recognized with the “Best of the States” award and a $300 prize, celebrating his innovation and commitment to AP’s high standards of journalistic excellence. This breaking news coverage stands as a reminder of the power and unpredictability of nature, as well as the courage and adaptability required to bring the story to those in its path.\n",
    "\"\"\"\n",
    "re3 = \"\"\"**AP Tornado Disaster Coverage: Midwest and South Tornadoes Wreak Havoc in 2012**\n",
    "\n",
    "*Harrisburg, IL & Cleveland, TN* — As the devastating tornadoes of 2012 tore through the Midwest and South, AP’s Chicago-based reporter Robert Ray delivered breaking news under extreme conditions, capturing the story with raw, on-the-ground reporting that brought the reality of the disaster to audiences nationwide. Opting to drive instead of fly, Ray navigated remote, tornado-stricken areas far from AP bureaus, coordinating in real time with the AP Central Regional Desk to relay immediate updates.\n",
    "\n",
    "Using a combination of Google Maps, iPhone navigation, and Doppler radar, Ray tracked tornado paths, capturing intense scenes of hail, heavy rain, and emergency response vehicles. His GoPro camera, mounted to the steering wheel, documented the journey, while his photojournalism uniquely highlighted the storm’s impact, including a stark, unforgettable image of a prosthetic leg found in the rubble alongside a hand-painted sign reading, “Found leg. Seriously.”\n",
    "\n",
    "In Cleveland, Tennessee, Ray was the first on the scene, conducting phone interviews with survivors and relaying real-time updates to AP Radio. Through close-up phone transcription, he provided direct quotes that conveyed both the power of nature and the resilience of those affected. Ray’s coverage integrated text, audio, and video, delivering a comprehensive, multi-format story of the unfolding disaster and offering vital public safety alerts to communities in the storm's path.\n",
    "\n",
    "This solo reporting effort underscored Ray’s journalistic duty in extreme weather, highlighting his adaptability and commitment to AP's high standards. Despite dangerous conditions and debris, he captured the survival stories of victims and the immense toll of the disaster. His coverage earned him the AP “Best of the States” award and a $300 prize for journalistic excellence, acknowledging his dedication to bringing an unfiltered, immediate account of the intense 2012 tornado season. \n",
    "\n",
    "Through Ray's eyes, the devastation and resilience of Middle America were documented in real time, offering a testament to the raw power of nature and the strength of those who endure it.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "docs = [re1, re2, re3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bac1b6a-1e41-40b9-8bf0-676b06fd705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"Hello world, this is a document.\"\n",
    "rewrite = \"Hello World, this is another document that is kinda similar.\"\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "original_embedding = model.encode([original])\n",
    "rewrite_embedding = model.encode([rewrite])\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarity = model.similarity(original_embedding, rewrite_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10dc831-d36e-4219-a957-e2f1cb8aa95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7908"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(similarity), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2e9c9f-df4a-4c88-90f3-cbfaa9496e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024) (3, 1024)\n",
      "tensor([[0.6638, 0.6535, 0.6852]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This model supports two prompts: \"s2p_query\" and \"s2s_query\" for sentence-to-passage and sentence-to-sentence tasks, respectively.\n",
    "# They are defined in `config_sentence_transformers.json`\n",
    "query_prompt_name = \"s2p_query\"\n",
    "queries = [\n",
    "    original\n",
    "]\n",
    "# ！The default dimension is 1024, if you need other dimensions, please clone the model and modify `modules.json` to replace `2_Dense_1024` with another dimension, e.g. `2_Dense_256` or `2_Dense_8192` !\n",
    "model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True)\n",
    "query_embeddings = model.encode(queries, prompt_name=query_prompt_name)\n",
    "doc_embeddings = model.encode(docs)\n",
    "print(query_embeddings.shape, doc_embeddings.shape)\n",
    "\n",
    "similarities = model.similarity(query_embeddings, doc_embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883c678d-c830-4b25-ad5b-62b7a1d13610",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers_modules.jinaai.xlm-roberta-flash-implementation.54b019f80aa9a0ce328a34ecb6b1d607af7d58de.rotary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjinaai/jina-embeddings-v3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m original_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode([original])\n\u001b[1;32m      3\u001b[0m rewrite_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(docs)\n",
      "File \u001b[0;32m/projappl/project_2011109/otto_venv/lib64/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:308\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    299\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[1;32m    302\u001b[0m     model_name_or_path,\n\u001b[1;32m    303\u001b[0m     token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    307\u001b[0m ):\n\u001b[0;32m--> 308\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    321\u001b[0m         model_name_or_path,\n\u001b[1;32m    322\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    330\u001b[0m     )\n",
      "File \u001b[0;32m/projappl/project_2011109/otto_venv/lib64/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1728\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1728\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(model_name_or_path)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-embeddings-v3/62a81741b58448ed8f691764cec7aa5d3c045e4c/custom_st.py:82\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adaptation_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m     name: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lora_adaptations)\n\u001b[1;32m     78\u001b[0m }\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_task \u001b[38;5;241m=\u001b[39m model_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault_task\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[1;32m     85\u001b[0m     tokenizer_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_seq_length\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:551\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    550\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mauto_map[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 551\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m     _ \u001b[38;5;241m=\u001b[39m hub_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:514\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[1;32m    502\u001b[0m final_module \u001b[38;5;241m=\u001b[39m get_cached_module_file(\n\u001b[1;32m    503\u001b[0m     repo_id,\n\u001b[1;32m    504\u001b[0m     module_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    513\u001b[0m )\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:212\u001b[0m, in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path)\u001b[0m\n\u001b[1;32m    210\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# reload in both cases\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[43mmodule_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/54b019f80aa9a0ce328a34ecb6b1d607af7d58de/modeling_lora.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XLMRobertaFlashConfig\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     XLMRobertaFlashConfig,\n\u001b[1;32m     17\u001b[0m     XLMRobertaModel,\n\u001b[1;32m     18\u001b[0m     XLMRobertaPreTrainedModel,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialized_weights\u001b[39m(\n\u001b[1;32m     23\u001b[0m     shape: Tuple[\u001b[38;5;28mint\u001b[39m], num_adaptations: \u001b[38;5;28mint\u001b[39m, init: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkaiming\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     25\u001b[0m     weight_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/xlm-roberta-flash-implementation/54b019f80aa9a0ce328a34ecb6b1d607af7d58de/modeling_xlm_roberta.py:33\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions, BertForPreTrainingOutput)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxlm_roberta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[1;32m     31\u001b[0m     XLMRobertaLMHead\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrotary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RotaryEmbedding\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Block\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XLMRobertaFlashConfig\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers_modules.jinaai.xlm-roberta-flash-implementation.54b019f80aa9a0ce328a34ecb6b1d607af7d58de.rotary'"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('jinaai/jina-embeddings-v3', trust_remote_code='True')\n",
    "original_embedding = model.encode([original])\n",
    "rewrite_embeddings = model.encode(docs)\n",
    "print(model.similarity(original_embedding, rewrite_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55530433-553c-470a-be0d-29568b74b30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
